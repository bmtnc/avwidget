% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_request.R
\name{llm_request}
\alias{llm_request}
\title{Make a request to an LLM API}
\usage{
llm_request(
  prompt,
  context = NULL,
  model = "claude-3-5-haiku-latest",
  api_key = Sys.getenv("ANTHROPIC_API_KEY"),
  max_tokens = 1000,
  temperature = 0,
  cache_key = NULL,
  response_type = "default",
  cache_dir = "llm_cache"
)
}
\arguments{
\item{prompt}{Character string containing the prompt}

\item{context}{Character string containing relevant context (optional)}

\item{model}{Character string specifying model to use}

\item{api_key}{Character string containing API key}

\item{max_tokens}{Integer specifying maximum tokens in response}

\item{temperature}{Numeric value controlling randomness (0-1)}

\item{cache_key}{Character string for caching (optional)}

\item{response_type}{Character string specifying type of response for cache naming}

\item{cache_dir}{Character string specifying cache directory (optional)}
}
\value{
Character string containing the LLM response
}
\description{
Core function for making LLM API requests with standardized parameters and error handling
}
